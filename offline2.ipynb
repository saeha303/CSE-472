{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve,accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mainly reading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=None\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.array(z, dtype=float)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logisticRegression(X, y, theta, bias, learning_rate, maxIteration, noFeatures):\n",
    "    # print('hi')\n",
    "    m=len(X)\n",
    "    for iteration in range(maxIteration):\n",
    "        # matrix multiplication\n",
    "        h = sigmoid(np.dot(X,theta)+bias)\n",
    "        gradient = np.dot(X.T,(h - y))/m\n",
    "        db=np.sum(h-y)/m\n",
    "        theta -= learning_rate * gradient\n",
    "        bias -= learning_rate * db\n",
    "    return theta,bias\n",
    "\n",
    "def predict(X, theta,bias):\n",
    "    probabilities = sigmoid(np.dot(X,theta)+bias)\n",
    "    predictions = [1 if prob >= 0.5 else 0 for prob in probabilities]\n",
    "    return np.array(predictions)\n",
    "\n",
    "def scalingFunction(scaling='standard'):\n",
    "    if scaling == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaling == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    \n",
    "    return scaler\n",
    "\n",
    "def normalize(X):\n",
    "    # m,n=X.shape\n",
    "    # for i in range(n):\n",
    "    #     X=(X-X.mean(axis=0))/X.std(axis=0)\n",
    "    return (X - X.mean()) / X.std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(target_col_name):\n",
    "    # drop null and fill null\n",
    "    dataframe.dropna(subset=[target_col_name], inplace=True)\n",
    "    dataframe.fillna(dataframe.mean(numeric_only=True),inplace=True)\n",
    "    # fill null for non-numeric columns\n",
    "    non_numerical_columns = dataframe.select_dtypes(include=['object']).columns\n",
    "    for column in non_numerical_columns:\n",
    "        mode_value = dataframe[column].mode()[0]\n",
    "        dataframe[column].fillna(mode_value,inplace=True)\n",
    "    # drop duplicates\n",
    "    dataframe.drop_duplicates(inplace=True)\n",
    "    # feature and target\n",
    "    features=dataframe.drop(target_col_name,axis=1)\n",
    "    target=dataframe[target_col_name]\n",
    "    # label encoding the target\n",
    "    encoder=LabelEncoder()\n",
    "    target=encoder.fit_transform(target)\n",
    "    # categorization and one-hot encoding\n",
    "    categorical_columns=features.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_columns:\n",
    "        features[col]=features[col].astype('category')\n",
    "    features=pd.get_dummies(features,columns=categorical_columns)\n",
    "    # scaling\n",
    "    candidate_columns=features.select_dtypes(exclude=['bool']).columns\n",
    "    # scaler=scalingFunction('standard')\n",
    "    scaler=scalingFunction('minmax')\n",
    "    features_scaled=features.copy()\n",
    "    features_scaled[candidate_columns]=scaler.fit_transform(features[candidate_columns])\n",
    "    # transform to dataframe\n",
    "    features_df=pd.DataFrame(features_scaled,columns=features.columns)\n",
    "    target_df=pd.DataFrame(target,columns=[target_col_name])\n",
    "    # print(features_df.head())\n",
    "    # print(target_df.head())\n",
    "    # adding for x0\n",
    "    features_df_normalized=normalize(features_df)\n",
    "    # features_df_normalized.insert(0, 'x0', 1)\n",
    "    # split into datasets\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(features_df, target_df, test_size=0.2, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df_normalized, target_df, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    # to numpy array\n",
    "    X = X_train.to_numpy()\n",
    "    # print(X.shape)\n",
    "    y = y_train.to_numpy().reshape(-1,1)\n",
    "    # print(y.shape)\n",
    "    maxIteration=1000\n",
    "    # noFeatures=features_df.shape[1]\n",
    "    noFeatures=features_df_normalized.shape[1]\n",
    "    # I was stuck here....\n",
    "    theta = np.zeros((noFeatures,1))\n",
    "    # print(theta.shape)\n",
    "    bias=0\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    theta_final,bias_final= logisticRegression(X, y, theta,bias, learning_rate, maxIteration, noFeatures)\n",
    "    X_test_np = X_test.to_numpy()\n",
    "    # print(X_test_np.shape)\n",
    "    # print(theta_final.shape)\n",
    "    predictions = predict(X_test_np, theta_final,bias_final)\n",
    "    print(predictions)\n",
    "    y_test_np = y_test.to_numpy().flatten()\n",
    "    print(y_test_np)\n",
    "    accuracy = np.mean(predictions == y_test_np)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    sensitivity = recall_score(y_test, predictions)\n",
    "    print(\"Sensitivity/Recall: \", sensitivity)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    print(\"Specificity: \", specificity)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    print(\"Precision: \", precision)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    y_prob = sigmoid(np.dot(X_test_np,theta_final))\n",
    "    auroc = roc_auc_score(y_test, y_prob)\n",
    "    print(\"AUROC: \", auroc)\n",
    "    precision_values, recall_values, _ = precision_recall_curve(y_test, y_prob)\n",
    "    aupr = auc(recall_values, precision_values)\n",
    "    print(\"AUPR: \", aupr)\n",
    "    model = LogisticRegression(max_iter=maxIteration)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test_np)\n",
    "    print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_2():\n",
    "    global dataframe\n",
    "    column_file = 'adult/adult.names'\n",
    "    data_file = 'adult/adult.data'\n",
    "    columns = []\n",
    "    with open(column_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if '|' not in line:  # Ignore lines starting with '|'\n",
    "                if ':' in line:\n",
    "                    # Extract the column name before the ':' punctuation mark\n",
    "                    col_name = line.split(':')[0].strip()\n",
    "                    columns.append(col_name)\n",
    "    columns.append('income-exceeds')\n",
    "    dataframe = pd.read_csv(data_file, header=None)\n",
    "    # print(dataframe)\n",
    "    dataframe.columns = columns\n",
    "    # print(dataframe)\n",
    "    dataframe.replace(' ?', np.nan, inplace=True)\n",
    "\n",
    "def read(input):\n",
    "    global dataframe\n",
    "    # file 1\n",
    "    if input == 1:\n",
    "        dataframe = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "        preprocessing('Churn')\n",
    "    # file 2\n",
    "    elif input == 2:\n",
    "        read_2()\n",
    "        preprocessing('income-exceeds')\n",
    "    # file 3\n",
    "    elif input == 3:\n",
    "        dataframe = pd.read_csv('creditcard.csv')\n",
    "        preprocessing('Class')\n",
    "    else:\n",
    "        print(\"Invalid input\")\n",
    "    # dataframe.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6176\\1326637357.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mode_value,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "[0 0 0 ... 0 0 1]\n",
      "Accuracy: 0.83819913952059\n",
      "Sensitivity/Recall:  0.6238303181534622\n",
      "Specificity:  0.908256880733945\n",
      "Precision:  0.6896551724137931\n",
      "F1 Score:  0.6550933508024893\n",
      "AUROC:  0.895106842865346\n",
      "AUPR:  0.7426320747552857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8538721573448064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_input = int(input(\"Enter 1, 2 or 3: \"))\n",
    "read(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
